# 分词器 Analyzer

Analyzer 是一个抽象类，切分词的具体规则由子类实现。内部通过TokenStream 实现，Tonkenizer 类和TokenFilter 类是TokenStream 的两个子类。
* Tokenizer 处理单个字符组成的字符流，读取Reader 对象中的数据，处理后转换成词汇单元
* TokenFilter完成文本过滤器的功能，但在使用过程中必须注意不同过滤器的使用顺序

#### Lucene 提供的分词器

* StopAnalyzer： 停用词分词器，能过滤词汇中特定的字符串和词汇，并且完成大写转小写的功能
* StandardAnalyzer： 标准分词器，根据空格和符号来完成分词，还可以完成数字、字母、email 地址、IP地址以及中文字符的分析处理，还可以支持过滤词表
* WhitespaceAnalyzer： 空格分词器，使用空格作为间隔符的词汇分词器
* SimpleAnalyzer： 简单分词器，基于西方文字符词汇分析的分词器，处理词汇单元时，以非字母字符作为分割符号。输出的词汇单元完成小写字符转换，去掉标点符号等分割符
* CJKAnalyzer： 二分法分词器，内部调用CJKTokenizer 分词器，对中文进行分词，同时使用StopFilter 过滤器完成过滤功能，可以实现中文的多元切分和停用词过滤
* KeywordAnalyzer： 关键词分词器，把整个输入作为一个单独词汇单元，方便特殊类型的文本进行索引。针对邮政编码、地址等文本信息使用关键词分词器进行索引建立非常方便


# Lucene 索引

### Lucene 字段类型

文档是Lucene 索引的最小单位，比文档更小的单位是字段，字段是文档的组成部分，由三部分组成：名称（name）、类型（type）和取值（value）。

字段的取值一般为文本类型（字符串、字符串流等）、二进制类型和数值类型

字段类型主要有：
* TextField：
