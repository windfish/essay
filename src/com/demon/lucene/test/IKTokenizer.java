package com.demon.lucene.test;

import org.wltea.analyzer.core.IKSegmenter;

/**
 * 使用IK 分词器，需要修改IKTokenizer 以兼容lucene 版本
 * @author xuliang
 * @since 2019年7月18日 下午5:31:03
 *
 */
public class IKTokenizer {

    /** IK 分词器实现 */
    private IKSegmenter ikSegmenter;
    
    
}
