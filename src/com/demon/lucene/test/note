# Lucene

Lucene 是一个提供搜索的类库，它专注于文本索引和搜索功能，并不是一个完整的搜索程序，搜索程序的其他模块（例如网页抓取、文档处理、服务器运行、用户界面等）需额外实现。

Lucene 能够把从文本解析处理的数据进行索引和搜索，并不关心数据来源、格式，只要数据能转换为文本格式即可。

Lucene 可以索引和搜索存储在文件中的如下数据（包括但不限于）：
* 远程web 服务器上的网页
* 本地文件系统上的文档
* 简单的文本文件
* word 文档
* xml 文档
* html 文档
* pdf 文档

一个简单的搜索引擎结构：
![](https://github.com/windfish/img/blob/master/notes-img/搜索/dd407fcd8eca9232eec875ca7e38fccb113.jpg?raw=true)

从web 或本地获取数据，将数据转为文档，然后进行文本提取，在通过索引程序生成索引，存入索引库，当用户输入关键字搜索时，从索引库中找到关键字对应的索引并显示对应的文档数据


# 分词器 Analyzer

Analyzer 是一个抽象类，切分词的具体规则由子类实现。内部通过TokenStream 实现，Tonkenizer 类和TokenFilter 类是TokenStream 的两个子类。
* Tokenizer 处理单个字符组成的字符流，读取Reader 对象中的数据，处理后转换成词汇单元
* TokenFilter完成文本过滤器的功能，但在使用过程中必须注意不同过滤器的使用顺序

#### Lucene 提供的分词器

* StopAnalyzer： 停用词分词器，能过滤词汇中特定的字符串和词汇，并且完成大写转小写的功能
* StandardAnalyzer： 标准分词器，根据空格和符号来完成分词，还可以完成数字、字母、email 地址、IP地址以及中文字符的分析处理，还可以支持过滤词表
* WhitespaceAnalyzer： 空格分词器，使用空格作为间隔符的词汇分词器
* SimpleAnalyzer： 简单分词器，基于西方文字符词汇分析的分词器，处理词汇单元时，以非字母字符作为分割符号。输出的词汇单元完成小写字符转换，去掉标点符号等分割符
* CJKAnalyzer： 二分法分词器，内部调用CJKTokenizer 分词器，对中文进行分词，同时使用StopFilter 过滤器完成过滤功能，可以实现中文的多元切分和停用词过滤
* KeywordAnalyzer： 关键词分词器，把整个输入作为一个单独词汇单元，方便特殊类型的文本进行索引。针对邮政编码、地址等文本信息使用关键词分词器进行索引建立非常方便


# 创建索引

1. Lucene 创建索引需要使用IndexWriter 对象，创建IndexWriter 对象需要两个参数，一个是IndexWriterConfig 对象，一个是索引的保存路径
2. IndexWriterConfig 设置创建索引使用哪种分词器以及索引的模式
3. IndexWriter 对象的addDocument() 用于添加文档，一次可以添加多个Document，最后调用commit() 方法生成索引
4. Document 表示文档，是Lucene 索引和搜索的基本单位，比文档小的单位是域，即字段。一个文档可以有多个域，FieldType 对象用于指定域的索引信息，如是否解析、是否存储、是否保存词项频率等


# 检索查询

索引建立之后就可以对其进行检索，当用户输入一个关键字后，对关键字进行处理，提高检索的效率，同时检索出更加有效的结果
* Lucene 中处理用户输入和查询关键词就是构建Query 对象的过程
* 搜索时，先实例化一个IndexSearch 对象，通过该对象的search() 方法完成搜索过程，参数为Query 对象。方法返回TopDocs 类型的文本集合
* 查询解析器QueryParser 用于生产Query 对象，需两个参数field 和analyzer，告诉QueryParser 在哪个字段内查找该关键字信息以及搜索时使用什么样的分词器

### Query 类型

* TermQuery： 词项搜索，最简单最常用的Query，可以在索引中搜索某一词条，词条就是key/value 对，key 是字段名，value 是字段中所包含的某个关键字
* BooleanQuery： 布尔搜索，一个组合Query，使用时把各种Query 对象添加进去并标明他们之间的逻辑关系
* RangeQuery： 范围搜索，有时用户需要查找满足一定范围的文档，如某一时间段的文档，回复条数在一定区间的文档。查询时需要有“开始词条”和“结束词条”
* PrefixQuery： 前缀搜索，使用前缀来进行查找，首先定义一个词条Term，该词条包含要查找的字段名以及关键字前缀，然后通过该词条创造一个PrefixQuery 对象
* PhraseQuery： 多关键字搜索，针对用户输入多个不同的关键字，这些关键字之前要么紧密相连，要么还插有其他无关的内容，此时使用PhraseQuery
* FuzzyQuery： 模糊搜索，简单识别两个相近的词语，例如：因拼写错误把"Trump"拼成"Trmp"或"Tramp"，可以使用FuzzyQuery
* WildcardQuery： 通配符搜索，用 ? 代替 * 



